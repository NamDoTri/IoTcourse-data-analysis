{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.base import clone\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":30,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/gender_submission.csv\n/kaggle/input/titanic/test.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Problem Definition & Goal"},{"metadata":{},"cell_type":"markdown","source":"The task is to predict if a passenger can survive the disaster. Since there are only 2 possible outcomes: alive and dead, I believe this is a classification problem, or more specifically, a binary classification one.      "},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis & Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"First, let's load the dataset and import all necessary modules"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntrain","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/titanic/test.csv')\ntest","execution_count":57,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"     PassengerId  Pclass                                          Name  \\\n0            892       3                              Kelly, Mr. James   \n1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n2            894       2                     Myles, Mr. Thomas Francis   \n3            895       3                              Wirz, Mr. Albert   \n4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n..           ...     ...                                           ...   \n413         1305       3                            Spector, Mr. Woolf   \n414         1306       1                  Oliva y Ocana, Dona. Fermina   \n415         1307       3                  Saether, Mr. Simon Sivertsen   \n416         1308       3                           Ware, Mr. Frederick   \n417         1309       3                      Peter, Master. Michael J   \n\n        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n0      male  34.5      0      0              330911    7.8292   NaN        Q  \n1    female  47.0      1      0              363272    7.0000   NaN        S  \n2      male  62.0      0      0              240276    9.6875   NaN        Q  \n3      male  27.0      0      0              315154    8.6625   NaN        S  \n4    female  22.0      1      1             3101298   12.2875   NaN        S  \n..      ...   ...    ...    ...                 ...       ...   ...      ...  \n413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n416    male   NaN      0      0              359309    8.0500   NaN        S  \n417    male   NaN      1      1                2668   22.3583   NaN        C  \n\n[418 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>1305</td>\n      <td>3</td>\n      <td>Spector, Mr. Woolf</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A.5. 3236</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>1306</td>\n      <td>1</td>\n      <td>Oliva y Ocana, Dona. Fermina</td>\n      <td>female</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PC 17758</td>\n      <td>108.9000</td>\n      <td>C105</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>1307</td>\n      <td>3</td>\n      <td>Saether, Mr. Simon Sivertsen</td>\n      <td>male</td>\n      <td>38.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>SOTON/O.Q. 3101262</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>1308</td>\n      <td>3</td>\n      <td>Ware, Mr. Frederick</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>359309</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>1309</td>\n      <td>3</td>\n      <td>Peter, Master. Michael J</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2668</td>\n      <td>22.3583</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Some general statistics to have an overview of the dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe(include='all')","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"        PassengerId    Survived      Pclass                      Name   Sex  \\\ncount    891.000000  891.000000  891.000000                       891   891   \nunique          NaN         NaN         NaN                       891     2   \ntop             NaN         NaN         NaN  Mannion, Miss. Margareth  male   \nfreq            NaN         NaN         NaN                         1   577   \nmean     446.000000    0.383838    2.308642                       NaN   NaN   \nstd      257.353842    0.486592    0.836071                       NaN   NaN   \nmin        1.000000    0.000000    1.000000                       NaN   NaN   \n25%      223.500000    0.000000    2.000000                       NaN   NaN   \n50%      446.000000    0.000000    3.000000                       NaN   NaN   \n75%      668.500000    1.000000    3.000000                       NaN   NaN   \nmax      891.000000    1.000000    3.000000                       NaN   NaN   \n\n               Age       SibSp       Parch  Ticket        Fare        Cabin  \\\ncount   714.000000  891.000000  891.000000     891  891.000000          204   \nunique         NaN         NaN         NaN     681         NaN          147   \ntop            NaN         NaN         NaN  347082         NaN  C23 C25 C27   \nfreq           NaN         NaN         NaN       7         NaN            4   \nmean     29.699118    0.523008    0.381594     NaN   32.204208          NaN   \nstd      14.526497    1.102743    0.806057     NaN   49.693429          NaN   \nmin       0.420000    0.000000    0.000000     NaN    0.000000          NaN   \n25%      20.125000    0.000000    0.000000     NaN    7.910400          NaN   \n50%      28.000000    0.000000    0.000000     NaN   14.454200          NaN   \n75%      38.000000    1.000000    0.000000     NaN   31.000000          NaN   \nmax      80.000000    8.000000    6.000000     NaN  512.329200          NaN   \n\n       Embarked  \ncount       889  \nunique        3  \ntop           S  \nfreq        644  \nmean        NaN  \nstd         NaN  \nmin         NaN  \n25%         NaN  \n50%         NaN  \n75%         NaN  \nmax         NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891.000000</td>\n      <td>204</td>\n      <td>889</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>891</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>681</td>\n      <td>NaN</td>\n      <td>147</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Mannion, Miss. Margareth</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>347082</td>\n      <td>NaN</td>\n      <td>C23 C25 C27</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>577</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>644</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>NaN</td>\n      <td>32.204208</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>NaN</td>\n      <td>49.693429</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>7.910400</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>14.454200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>31.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>512.329200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe(include='all')","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"        PassengerId      Pclass                       Name   Sex         Age  \\\ncount    418.000000  418.000000                        418   418  332.000000   \nunique          NaN         NaN                        418     2         NaN   \ntop             NaN         NaN  Carlsson, Mr. Carl Robert  male         NaN   \nfreq            NaN         NaN                          1   266         NaN   \nmean    1100.500000    2.265550                        NaN   NaN   30.272590   \nstd      120.810458    0.841838                        NaN   NaN   14.181209   \nmin      892.000000    1.000000                        NaN   NaN    0.170000   \n25%      996.250000    1.000000                        NaN   NaN   21.000000   \n50%     1100.500000    3.000000                        NaN   NaN   27.000000   \n75%     1204.750000    3.000000                        NaN   NaN   39.000000   \nmax     1309.000000    3.000000                        NaN   NaN   76.000000   \n\n             SibSp       Parch    Ticket        Fare            Cabin Embarked  \ncount   418.000000  418.000000       418  417.000000               91      418  \nunique         NaN         NaN       363         NaN               76        3  \ntop            NaN         NaN  PC 17608         NaN  B57 B59 B63 B66        S  \nfreq           NaN         NaN         5         NaN                3      270  \nmean      0.447368    0.392344       NaN   35.627188              NaN      NaN  \nstd       0.896760    0.981429       NaN   55.907576              NaN      NaN  \nmin       0.000000    0.000000       NaN    0.000000              NaN      NaN  \n25%       0.000000    0.000000       NaN    7.895800              NaN      NaN  \n50%       0.000000    0.000000       NaN   14.454200              NaN      NaN  \n75%       1.000000    0.000000       NaN   31.500000              NaN      NaN  \nmax       8.000000    9.000000       NaN  512.329200              NaN      NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>418.000000</td>\n      <td>418.000000</td>\n      <td>418</td>\n      <td>418</td>\n      <td>332.000000</td>\n      <td>418.000000</td>\n      <td>418.000000</td>\n      <td>418</td>\n      <td>417.000000</td>\n      <td>91</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>418</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>363</td>\n      <td>NaN</td>\n      <td>76</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Carlsson, Mr. Carl Robert</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>PC 17608</td>\n      <td>NaN</td>\n      <td>B57 B59 B63 B66</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>266</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>270</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1100.500000</td>\n      <td>2.265550</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>30.272590</td>\n      <td>0.447368</td>\n      <td>0.392344</td>\n      <td>NaN</td>\n      <td>35.627188</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>120.810458</td>\n      <td>0.841838</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.181209</td>\n      <td>0.896760</td>\n      <td>0.981429</td>\n      <td>NaN</td>\n      <td>55.907576</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>892.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.170000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>996.250000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>7.895800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1100.500000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>27.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>14.454200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1204.750000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>39.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>31.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1309.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>76.000000</td>\n      <td>8.000000</td>\n      <td>9.000000</td>\n      <td>NaN</td>\n      <td>512.329200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Some insights observed from the stats table above:  \n- There are 3 different classes of ticket on the Titanic, but the mean of the train set is above 2.3, which means the number of First class passengers is far lower than that of those in Second and Third class. Fortunately, this is also the case in the test set, which means the train-test splitting was done pretty well, so we do not need to care about skewed train set.\n- Column PassengerId is just a sequence of number to distinguish between each row, so this can be dropped without affecting the model performance.\n- Columns with categorical values such as Pclass, Sex, and Embarked can be applied with one hot encoding to ensure that the model does not mistake them with continuous values\n"},{"metadata":{},"cell_type":"markdown","source":"Some other additional observations:  \n- It is not trivial to impute missing values in column Cabin as there are plenty of such instances and the correlations between this column and other features avaiable in our datasets are not that explicit. One possible way to tackle this would be to combine this dataset with some other dataset which has passenger names and the cabin they were in. Another the way is to find which cabins each Pclass were assigned in, then fill in the missing values in column Cabin based on our available data on ticket class. \n- There are only two gender values present in this dataset, under the format of string \"male\" and \"female\". We can use a one-hot encoder for this."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Sex.unique()","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"array(['male', 'female'], dtype=object)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Another interesting information is that the number of ticket (681) is fewer than the number of passengers (891). This is supposedly because the children used the same tickets with their adult companions?"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train.Ticket.unique())","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"681"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.nan in train.Ticket.unique()","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"False"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Handling missing data"},{"metadata":{},"cell_type":"markdown","source":"## Place of embarkation"},{"metadata":{},"cell_type":"markdown","source":"There are two missing values in column Embarked, so let's have a look at them to see if we can find a way to handle this"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[ train.Embarked.isna()]","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"     PassengerId  Survived  Pclass                                       Name  \\\n61            62         1       1                        Icard, Miss. Amelie   \n829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n\n        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked  \n61   female  38.0      0      0  113572  80.0   B28      NaN  \n829  female  62.0      0      0  113572  80.0   B28      NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>61</th>\n      <td>62</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Icard, Miss. Amelie</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113572</td>\n      <td>80.0</td>\n      <td>B28</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>829</th>\n      <td>830</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n      <td>female</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113572</td>\n      <td>80.0</td>\n      <td>B28</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"When attempting to find information about these two people, I came across this [link](https://www.encyclopedia-titanica.org/titanic-survivor/amelia-icard.html), which is quite useful. From this, we can conclude that these people embarked from Southampton, so these 2 values should be imputed with \"S\""},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cleaned = train.copy()\ntrain_cleaned.at[train_cleaned.Embarked.isna(), \"Embarked\"] = \"S\"","execution_count":37,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Age"},{"metadata":{},"cell_type":"markdown","source":"There are almost 200 data points with missing age values. There are 3 possible ways which I suppose can be used to handle this problem:  \n- Replace all of them with the mean value: this is probably the easiest way to go, but since the standard deviation is quite large, this might not be the most ideal option.\n- Replace with the median\n- Use a regression model to impute those missing values\n\nFor now I will use the first method because of its simplicity, then if there is enough time I will attempt with the third option."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cleaned.at[train_cleaned.Age.isna(), \"Age\"] = train_cleaned.Age.mean()","execution_count":38,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see what we have gotten so far:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cleaned.describe(include='all')","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"        PassengerId    Survived      Pclass                      Name   Sex  \\\ncount    891.000000  891.000000  891.000000                       891   891   \nunique          NaN         NaN         NaN                       891     2   \ntop             NaN         NaN         NaN  Mannion, Miss. Margareth  male   \nfreq            NaN         NaN         NaN                         1   577   \nmean     446.000000    0.383838    2.308642                       NaN   NaN   \nstd      257.353842    0.486592    0.836071                       NaN   NaN   \nmin        1.000000    0.000000    1.000000                       NaN   NaN   \n25%      223.500000    0.000000    2.000000                       NaN   NaN   \n50%      446.000000    0.000000    3.000000                       NaN   NaN   \n75%      668.500000    1.000000    3.000000                       NaN   NaN   \nmax      891.000000    1.000000    3.000000                       NaN   NaN   \n\n               Age       SibSp       Parch  Ticket        Fare        Cabin  \\\ncount   891.000000  891.000000  891.000000     891  891.000000          204   \nunique         NaN         NaN         NaN     681         NaN          147   \ntop            NaN         NaN         NaN  347082         NaN  C23 C25 C27   \nfreq           NaN         NaN         NaN       7         NaN            4   \nmean     29.699118    0.523008    0.381594     NaN   32.204208          NaN   \nstd      13.002015    1.102743    0.806057     NaN   49.693429          NaN   \nmin       0.420000    0.000000    0.000000     NaN    0.000000          NaN   \n25%      22.000000    0.000000    0.000000     NaN    7.910400          NaN   \n50%      29.699118    0.000000    0.000000     NaN   14.454200          NaN   \n75%      35.000000    1.000000    0.000000     NaN   31.000000          NaN   \nmax      80.000000    8.000000    6.000000     NaN  512.329200          NaN   \n\n       Embarked  \ncount       891  \nunique        3  \ntop           S  \nfreq        646  \nmean        NaN  \nstd         NaN  \nmin         NaN  \n25%         NaN  \n50%         NaN  \n75%         NaN  \nmax         NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891.000000</td>\n      <td>204</td>\n      <td>891</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>891</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>681</td>\n      <td>NaN</td>\n      <td>147</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Mannion, Miss. Margareth</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>347082</td>\n      <td>NaN</td>\n      <td>C23 C25 C27</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>577</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>646</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>NaN</td>\n      <td>32.204208</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.002015</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>NaN</td>\n      <td>49.693429</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>7.910400</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.699118</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>14.454200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>35.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>31.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>512.329200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now that the dataset is much cleaner now with only one column with missing data, we can move on to prepare our data and train models"},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"First, we can start with encoding columns with categorical data types, which are Pclass, Embarked and Sex."},{"metadata":{},"cell_type":"markdown","source":"## Pclass encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_prepared = train_cleaned.copy()\npclass_onehot_encoder = OneHotEncoder()\npclass_onehot_encode = pclass_onehot_encoder.fit_transform(train_prepared[['Pclass']]).toarray()","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for cat in pclass_onehot_encoder.categories_[0]:\n    train_prepared.insert(2, 'Pclass_'+str(cat), pclass_onehot_encode[:,cat-1])","execution_count":41,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Embarked encoding"},{"metadata":{},"cell_type":"markdown","source":"Next, we also need to encode the Embarked column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"embarked_1hot_encoder = OneHotEncoder()\nembarked_1hot_encode = embarked_1hot_encoder.fit_transform(train_prepared[['Embarked']]).toarray()","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for cat in embarked_1hot_encoder.categories_[0]:\n    insert_index = len(train_prepared.columns)-1\n    value_index = np.where(embarked_1hot_encoder.categories_[0] == cat)[0][0]\n    train_prepared.insert(insert_index, \"Embarked_\"+cat, embarked_1hot_encode[:, value_index])","execution_count":43,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sex encoding"},{"metadata":{},"cell_type":"markdown","source":"And last but not least, the sex of each passenger:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sex_1hot_encoder = OneHotEncoder()\nsex_1hot_encode = sex_1hot_encoder.fit_transform(train_prepared[[\"Sex\"]]).toarray()","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for cat in sex_1hot_encoder.categories_[0]:\n    insert_index = len(train_prepared.columns)-1\n    value_index = np.where(sex_1hot_encoder.categories_[0] == cat)[0][0]\n    train_prepared.insert(insert_index, \"Sex_\"+cat, sex_1hot_encode[:, value_index])","execution_count":45,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can drop all the unnecessary columns and ones which takes long time or more effort to clean, then we can start training some models and see what works best in this case."},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_columns = ['PassengerId', 'Name', 'Ticket','Cabin', 'Pclass', 'Sex', 'Embarked']\ntrain_prepared = train_prepared.drop(drop_columns, axis=1)\ntrain_prepared","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"     Survived  Pclass_3  Pclass_2  Pclass_1        Age  SibSp  Parch     Fare  \\\n0           0       1.0       0.0       0.0  22.000000      1      0   7.2500   \n1           1       0.0       0.0       1.0  38.000000      1      0  71.2833   \n2           1       1.0       0.0       0.0  26.000000      0      0   7.9250   \n3           1       0.0       0.0       1.0  35.000000      1      0  53.1000   \n4           0       1.0       0.0       0.0  35.000000      0      0   8.0500   \n..        ...       ...       ...       ...        ...    ...    ...      ...   \n886         0       0.0       1.0       0.0  27.000000      0      0  13.0000   \n887         1       0.0       0.0       1.0  19.000000      0      0  30.0000   \n888         0       1.0       0.0       0.0  29.699118      1      2  23.4500   \n889         1       0.0       0.0       1.0  26.000000      0      0  30.0000   \n890         0       1.0       0.0       0.0  32.000000      0      0   7.7500   \n\n     Embarked_C  Embarked_Q  Embarked_S  Sex_female  Sex_male  \n0           0.0         0.0         1.0         0.0       1.0  \n1           1.0         0.0         0.0         1.0       0.0  \n2           0.0         0.0         1.0         1.0       0.0  \n3           0.0         0.0         1.0         1.0       0.0  \n4           0.0         0.0         1.0         0.0       1.0  \n..          ...         ...         ...         ...       ...  \n886         0.0         0.0         1.0         0.0       1.0  \n887         0.0         0.0         1.0         1.0       0.0  \n888         0.0         0.0         1.0         1.0       0.0  \n889         1.0         0.0         0.0         0.0       1.0  \n890         0.0         1.0         0.0         0.0       1.0  \n\n[891 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass_3</th>\n      <th>Pclass_2</th>\n      <th>Pclass_1</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>38.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>26.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>35.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>35.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>27.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>19.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>29.699118</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>26.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>32.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Split predictors and target"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_prepared.drop('Survived', axis=1)\ny_train = train_prepared.Survived","execution_count":47,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model selection and training"},{"metadata":{},"cell_type":"markdown","source":"Now that we have our data cleaned, encoded into numerical values and split into predictors and target, it's time to train our classification models. I will start with a single Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid_search_params = {\n    'criterion': ['gini','entropy'],\n    'max_depth': [3, 4, None],\n}\ntree_grid_search = GridSearchCV(DecisionTreeClassifier(), tree_grid_search_params, scoring='accuracy', cv=4, return_train_score=True)\ntree_grid_search.fit(X_train, y_train)\ntree_grid_search.best_score_","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"0.8193198804185352"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The result is not that impressive, but hopefully a collection of trees can do better. To save some training time, I will take advantage of the parameters of the best tree:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_grid_search.best_params_","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"{'criterion': 'entropy', 'max_depth': 3}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr_grid_search_params = {\n    'n_estimators': [10, 50, 100],\n    'criterion': ['entropy'],\n    'max_depth': np.arange(3,20)\n}\nrfr_grid_search = GridSearchCV(RandomForestClassifier(), rfr_grid_search_params, scoring='accuracy', cv=4, return_train_score=True)\nrfr_grid_search.fit(X_train, y_train)\nrfr_grid_search.best_score_","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"0.8339039712358098"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr_grid_search.best_params_","execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"{'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 50}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"As can be seen, the performance is slightly improved, but not that great. Let's try with the K Neighbors algorithms to see how it does: "},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_clf = KNeighborsClassifier()\nknn_scores = cross_val_score(knn_clf, X_train, y_train, scoring='accuracy')\nknn_scores.mean()","execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"0.7037474107086812"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"So it performs even worse. One of the possible reasons for why these models fall short of my expectations is that all the features are being used. Maybe if only the ones with high correlation is chosen, our models may perform better. Let's find out:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in sorted(zip(X_train.columns, rfr_grid_search.best_estimator_.feature_importances_),key=lambda x: x[1]):\n    print(f)","execution_count":53,"outputs":[{"output_type":"stream","text":"('Embarked_Q', 0.009104966811795201)\n('Embarked_C', 0.01376986882301593)\n('Embarked_S', 0.017351584834613312)\n('Pclass_2', 0.030923310352367395)\n('Parch', 0.044292743768548686)\n('Pclass_1', 0.044825994146182685)\n('SibSp', 0.054221402278952696)\n('Pclass_3', 0.062183070027481246)\n('Sex_male', 0.15976383823778695)\n('Age', 0.1665879523748859)\n('Fare', 0.19783860102161563)\n('Sex_female', 0.19913666732275442)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"For the sake of experimentality, I will only train the model with the top 5 most important features and see if that has any considerable impact on the model performance in general. Once again, I will use the parameters of the best estimators:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_selected = X_train[['Sex_male', 'Fare', 'Age', 'Pclass_3']]","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr_clf2 = RandomForestClassifier(criterion='entropy', max_depth=8)\nrfr_clf2_scores = cross_val_score(rfr_clf2, X_train_selected, y_train, cv=5, scoring='accuracy')\nrfr_clf2_scores.mean()","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"0.8305316678174629"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_clf2 = KNeighborsClassifier()\nknn_clf2_scores = cross_val_score(knn_clf2, X_train_selected, y_train, cv=5, scoring='accuracy')\nknn_clf2_scores.mean()","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"0.6891657774151027"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The performance did not seem to improve that much with a smaller set of features, but I think it was worth trying. I also reran the above code several times and in some cases, the accuracy of our Random Forest Classifier was slightly improved with only the 5 most important features, but in general they are roughly the same. The K Neighbors classifier performs even worse for some reasons. Unfortunately, the column Survived was nowhere to be found in the test set, so the above results are only on the train set. "}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}